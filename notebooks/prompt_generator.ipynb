{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamimos/anaconda3/envs/transformer_confidence_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_metric' from 'datasets' (/Users/adamimos/anaconda3/envs/transformer_confidence_env/lib/python3.9/site-packages/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbigbench\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Import modules from the codebase\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_confidence\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbigbench_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BigBenchLoader\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_confidence\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_generator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptBuilder\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformer_confidence\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_generator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt_templates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     FIRST_ORDER_PROMPT,\n\u001b[1;32m     13\u001b[0m     SECOND_ORDER_PROMPT_2AFC,\n\u001b[1;32m     14\u001b[0m     SECOND_ORDER_PROMPT_CONTINUOUS,\n\u001b[1;32m     15\u001b[0m     SECOND_ORDER_PROMPT_INTUITIVE\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/transformer-confidence/transformer_confidence/data_loader/bigbench_loader.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbigbench\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_task\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBigBenchLoader\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, task_name):\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer_confidence_env/lib/python3.9/site-packages/bigbench/api/json_task.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbigbench\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_utils\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbigbench\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtask\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbigbench\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask_metrics\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmetrics\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbigbench\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresults\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mresults_api\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer_confidence_env/lib/python3.9/site-packages/bigbench/api/task_metrics.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_metric\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logsumexp\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mt5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_metric' from 'datasets' (/Users/adamimos/anaconda3/envs/transformer_confidence_env/lib/python3.9/site-packages/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import bigbench\n",
    "\n",
    "# Import modules from the codebase\n",
    "from transformer_confidence.data_loader.bigbench_loader import BigBenchLoader\n",
    "from transformer_confidence.prompt_generator.prompt_builder import PromptBuilder\n",
    "from transformer_confidence.prompt_generator.prompt_templates import (\n",
    "    FIRST_ORDER_PROMPT,\n",
    "    SECOND_ORDER_PROMPT_2AFC,\n",
    "    SECOND_ORDER_PROMPT_CONTINUOUS,\n",
    "    SECOND_ORDER_PROMPT_INTUITIVE\n",
    ")\n",
    "from transformer_confidence.nndif_client.nndif_api import NNDIFClient\n",
    "from transformer_confidence.utils.storage import StorageManager\n",
    "\n",
    "# Import NNsight and configure API key\n",
    "import nnsight\n",
    "from nnsight import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "\n",
    "def fetch_bigbench_task_jsons(task_name, ref='main', token=None):\n",
    "    \"\"\"\n",
    "    Fetches all JSON files from a specific BigBench task folder and its subfolders.\n",
    "\n",
    "    Parameters:\n",
    "        task_name (str): Name of the task folder in bigbench/benchmark_tasks\n",
    "        ref (str): The name of the commit/branch/tag. Default is 'main'.\n",
    "        token (str): GitHub Personal Access Token for authenticated requests (optional)\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are file paths and values are parsed JSON contents\n",
    "    \"\"\"\n",
    "    base_url = 'https://api.github.com/repos/google/BIG-bench/contents'\n",
    "    task_path = f'bigbench/benchmark_tasks/{task_name}'\n",
    "    headers = {'Accept': 'application/vnd.github.v3+json'}\n",
    "    if token:\n",
    "        headers['Authorization'] = f'token {token}'\n",
    "\n",
    "    def fetch_contents(path):\n",
    "        url = f'{base_url}/{path}?ref={ref}'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f'Error fetching contents: {response.status_code} {response.reason}')\n",
    "        return response.json()\n",
    "\n",
    "    def process_item(item):\n",
    "        if item['type'] == 'file' and item['name'].endswith('.json'):\n",
    "            file_content = requests.get(item['download_url'], headers=headers).content\n",
    "            return {item['path']: json.loads(file_content.decode('utf-8'))}\n",
    "        elif item['type'] == 'dir':\n",
    "            return process_folder(item['path'])\n",
    "        return {}\n",
    "\n",
    "    def process_folder(folder_path):\n",
    "        contents = fetch_contents(folder_path)\n",
    "        result = {}\n",
    "        for item in contents:\n",
    "            result.update(process_item(item))\n",
    "        return result\n",
    "\n",
    "    return process_folder(task_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_125m_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 134228992, 'model_family': 'BIG-G T=0', 'model_name': '125m', 'non_embedding_params': 134228992, 'total_params': 166996992, 'training_batch_size': 262144, 'training_steps': 649200}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.11}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.022, 'normalized_aggregate_score': 2.1999999999999997}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_125m_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 134228992, 'model_family': 'BIG-G T=1', 'model_name': '125m', 'non_embedding_params': 134228992, 'total_params': 166996992, 'training_batch_size': 262144, 'training_steps': 649200}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.13}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.026000000000000002, 'normalized_aggregate_score': 2.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_128b_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 137440272384, 'model_family': 'BIG-G T=0', 'model_name': '128b', 'non_embedding_params': 137440272384, 'total_params': 137702416384, 'training_batch_size': 262144, 'training_steps': 2571500}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.98}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.86}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.61}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.05}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.02}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.504, 'normalized_aggregate_score': 50.4}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_128b_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 137440272384, 'model_family': 'BIG-G T=1', 'model_name': '128b', 'non_embedding_params': 137440272384, 'total_params': 137702416384, 'training_batch_size': 262144, 'training_steps': 2571500}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.53}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.54}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.21}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.26, 'normalized_aggregate_score': 26.0}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_16m_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 16780288, 'model_family': 'BIG-G T=0', 'model_name': '16m', 'non_embedding_params': 16780288, 'total_params': 33164288, 'training_batch_size': 262144, 'training_steps': 1194900}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.006, 'normalized_aggregate_score': 0.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_16m_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 16780288, 'model_family': 'BIG-G T=1', 'model_name': '16m', 'non_embedding_params': 16780288, 'total_params': 33164288, 'training_batch_size': 262144, 'training_steps': 1194900}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.008, 'normalized_aggregate_score': 0.8}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_1b_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 1073784832, 'model_family': 'BIG-G T=0', 'model_name': '1b', 'non_embedding_params': 1073784832, 'total_params': 1139320832, 'training_batch_size': 262144, 'training_steps': 541400}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.35}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.04}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.078, 'normalized_aggregate_score': 7.8}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_1b_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 1073784832, 'model_family': 'BIG-G T=1', 'model_name': '1b', 'non_embedding_params': 1073784832, 'total_params': 1139320832, 'training_batch_size': 262144, 'training_steps': 541400}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.19}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.05}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.048, 'normalized_aggregate_score': 4.8}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_244m_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 262161280, 'model_family': 'BIG-G T=0', 'model_name': '244m', 'non_embedding_params': 262161280, 'total_params': 303121280, 'training_batch_size': 262144, 'training_steps': 1010500}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.21}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.02}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.046, 'normalized_aggregate_score': 4.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_244m_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 262161280, 'model_family': 'BIG-G T=1', 'model_name': '244m', 'non_embedding_params': 262161280, 'total_params': 303121280, 'training_batch_size': 262144, 'training_steps': 1010500}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.16}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.04}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.04, 'normalized_aggregate_score': 4.0}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_27b_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 28991404032, 'model_family': 'BIG-G T=0', 'model_name': '27b', 'non_embedding_params': 28991404032, 'total_params': 29188012032, 'training_batch_size': 262144, 'training_steps': 503200}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.84}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.14}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.196, 'normalized_aggregate_score': 19.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_27b_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 28991404032, 'model_family': 'BIG-G T=1', 'model_name': '27b', 'non_embedding_params': 28991404032, 'total_params': 29188012032, 'training_batch_size': 262144, 'training_steps': 503200}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.5}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.06}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.112, 'normalized_aggregate_score': 11.200000000000001}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_2b_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 2097218560, 'model_family': 'BIG-G T=0', 'model_name': '2b', 'non_embedding_params': 2097218560, 'total_params': 2179138560, 'training_batch_size': 262144, 'training_steps': 521000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.45}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.07}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.10400000000000001, 'normalized_aggregate_score': 10.4}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_2b_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 2097218560, 'model_family': 'BIG-G T=1', 'model_name': '2b', 'non_embedding_params': 2097218560, 'total_params': 2179138560, 'training_batch_size': 262144, 'training_steps': 521000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.11}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.028, 'normalized_aggregate_score': 2.8000000000000003}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_2m_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 2098048, 'model_family': 'BIG-G T=0', 'model_name': '2m', 'non_embedding_params': 2098048, 'total_params': 10290048, 'training_batch_size': 262144, 'training_steps': 1000000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.006, 'normalized_aggregate_score': 0.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_2m_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 2098048, 'model_family': 'BIG-G T=1', 'model_name': '2m', 'non_embedding_params': 2098048, 'total_params': 10290048, 'training_batch_size': 262144, 'training_steps': 1000000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.006, 'normalized_aggregate_score': 0.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_422m_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 453009408, 'model_family': 'BIG-G T=0', 'model_name': '422m', 'non_embedding_params': 453009408, 'total_params': 502161408, 'training_batch_size': 262144, 'training_steps': 572000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.23}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.052000000000000005, 'normalized_aggregate_score': 5.2}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_422m_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 453009408, 'model_family': 'BIG-G T=1', 'model_name': '422m', 'non_embedding_params': 453009408, 'total_params': 502161408, 'training_batch_size': 262144, 'training_steps': 572000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.11}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.024, 'normalized_aggregate_score': 2.4}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_4b_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 3623973888, 'model_family': 'BIG-G T=0', 'model_name': '4b', 'non_embedding_params': 3623973888, 'total_params': 3722277888, 'training_batch_size': 262144, 'training_steps': 519000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.72}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.11}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.16599999999999998, 'normalized_aggregate_score': 16.599999999999998}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_4b_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 3623973888, 'model_family': 'BIG-G T=1', 'model_name': '4b', 'non_embedding_params': 3623973888, 'total_params': 3722277888, 'training_batch_size': 262144, 'training_steps': 519000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.34}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.05}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.078, 'normalized_aggregate_score': 7.8}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_53m_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 56629632, 'model_family': 'BIG-G T=0', 'model_name': '53m', 'non_embedding_params': 56629632, 'total_params': 81205632, 'training_batch_size': 262144, 'training_steps': 1000000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.008, 'normalized_aggregate_score': 0.8}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_53m_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 56629632, 'model_family': 'BIG-G T=1', 'model_name': '53m', 'non_embedding_params': 56629632, 'total_params': 81205632, 'training_batch_size': 262144, 'training_steps': 1000000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.03}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.006, 'normalized_aggregate_score': 0.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_8b_T=0.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 8590102528, 'model_family': 'BIG-G T=0', 'model_name': '8b', 'non_embedding_params': 8590102528, 'total_params': 8721174528, 'training_batch_size': 262144, 'training_steps': 501900}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.8}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.16}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.194, 'normalized_aggregate_score': 19.400000000000002}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_BIG-G_8b_T=1.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 1, 'top-k': 40}, 'description': 'A dense decoder-only transformer architecture, similar to that in LaMDA (https://arxiv.org/abs/2201.08239). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 8590102528, 'model_family': 'BIG-G T=1', 'model_name': '8b', 'non_embedding_params': 8590102528, 'total_params': 8721174528, 'training_batch_size': 262144, 'training_steps': 501900}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.19}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.07}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.054, 'normalized_aggregate_score': 5.4}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-13B.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 13000000000, 'model_family': 'GPT', 'model_name': 'GPT-3 13B', 'non_embedding_params': 13000000000, 'total_params': 13000000000, 'training_batch_size': 2000000, 'training_steps': 150000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.95}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.06}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.02}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.206, 'normalized_aggregate_score': 20.599999999999998}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-200B.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 200000000000, 'model_family': 'GPT', 'model_name': 'GPT-3 200B', 'non_embedding_params': 200000000000, 'total_params': 200000000000, 'training_batch_size': 4000000, 'training_steps': 75000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 1.78}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 1.28}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.23}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.66, 'normalized_aggregate_score': 66.0}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-3B.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 3000000000, 'model_family': 'GPT', 'model_name': 'GPT-3 3B', 'non_embedding_params': 3000000000, 'total_params': 3000000000, 'training_batch_size': 1000000, 'training_steps': 300000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.48}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.096, 'normalized_aggregate_score': 9.6}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-6B.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 6000000000, 'model_family': 'GPT', 'model_name': 'GPT-3 6B', 'non_embedding_params': 6000000000, 'total_params': 6000000000, 'training_batch_size': 2000000, 'training_steps': 150000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.5}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.01}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.102, 'normalized_aggregate_score': 10.2}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-Large.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 760000000, 'model_family': 'GPT', 'model_name': 'GPT-3 Large', 'non_embedding_params': 760000000, 'total_params': 760000000, 'training_batch_size': 500000, 'training_steps': 600000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.05}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.01, 'normalized_aggregate_score': 1.0}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-Medium.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 350000000, 'model_family': 'GPT', 'model_name': 'GPT-3 Medium', 'non_embedding_params': 350000000, 'total_params': 350000000, 'training_batch_size': 500000, 'training_steps': 600000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.21}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.041999999999999996, 'normalized_aggregate_score': 4.199999999999999}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-Small.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 125000000, 'model_family': 'GPT', 'model_name': 'GPT-3 Small', 'non_embedding_params': 125000000, 'total_params': 125000000, 'training_batch_size': 500000, 'training_steps': 600000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.05}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.01, 'normalized_aggregate_score': 1.0}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}, 'bigbench/benchmark_tasks/simple_arithmetic/results/scores_GPT_GPT-3-XL.json': {'model': {'additional_details': 'No additional information about training or evaluation protocol for this model.', 'decoding_params': {'temperature': 0}, 'description': 'A dense decoder-only transformer architecture, corresponding to a previously published GPT-3 model (https://arxiv.org/abs/2005.14165). See the BIG-bench paper for details.', 'flop_matched_non_embedding_params': 1300000000, 'model_family': 'GPT', 'model_name': 'GPT-3 XL', 'non_embedding_params': 1300000000, 'total_params': 1300000000, 'training_batch_size': 1000000, 'training_steps': 300000}, 'scores': [{'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.07}, 'subtask_description': 'Exact string match arithmetic on 1 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 2 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 3 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 4 digits.'}, {'high_score': 1.0, 'low_score': 0.0, 'number_of_shots': 0, 'preferred_score': 'exact_str_match', 'score_dict': {'exact_str_match': 0.0}, 'subtask_description': 'Exact string match arithmetic on 5 digits.'}, {'high_score': 100, 'low_score': 0, 'number_of_shots': 0, 'preferred_score': 'normalized_aggregate_score', 'score_dict': {'exact_str_match': 0.014000000000000002, 'normalized_aggregate_score': 1.4000000000000001}, 'subtask_description': 'simple_arithmetic'}], 'task': {'task_name': 'simple_arithmetic'}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "owner = 'google'\n",
    "repo = 'BIG-bench'\n",
    "task_name = 'simple_arithmetic'\n",
    "filepath = f'bigbench/benchmark_tasks/{task_name}/task.json'\n",
    "ref = 'main'  # or specify a commit hash or branch name\n",
    "\n",
    "# If you have a GitHub token, you can provide it here to increase rate limits\n",
    "token = None  # Replace with your token if available\n",
    "\n",
    "task_data = fetch_bigbench_task_jsons(task_name, ref, token)\n",
    "\n",
    "print(task_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-confidence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
